{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book Recommendation System\n",
    "___\n",
    "\n",
    "- model: User-based collaborative filtering + matrix factorization using neural networks\n",
    "- dataset: [goodreads rating 10k](https://github.com/zygmuntz/goodbooks-10k)\n",
    "- modules: sklearn, keras\n",
    "\n",
    "**Outline**:\n",
    "\n",
    "1. input function for getting rating from a new user\n",
    "2. calculate the similarity between users and new user using cosine similarity (find the closest user)\n",
    "3. use matrix factorization to calculate book rating for all the user\n",
    "4. recommend top 10 books for new user based on similar user's book recommendation from matrix factorization\n",
    "\n",
    "\n",
    "**reference**:\n",
    "* matrix-factorization tutuorials: \n",
    "    - https://course.fast.ai/videos/?lesson=4\n",
    "    - https://medium.com/@jdwittenauer/deep-learning-with-keras-recommender-systems-e7b99cb29929\n",
    "    - https://towardsdatascience.com/building-a-book-recommendation-system-using-keras-1fba34180699\n",
    "* user-based collaborative filtering: \n",
    "    - https://medium.com/@wwwbbb8510/comparison-of-user-based-and-item-based-collaborative-filtering-f58a1c8a3f1d\n",
    "    - https://medium.com/sfu-cspmp/recommendation-systems-user-based-collaborative-filtering-using-n-nearest-neighbors-bf7361dc24e0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import spatial\n",
    "import random\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating = pd.read_csv('goodbooks-10k-master/ratings.csv')\n",
    "df_books = pd.read_csv('goodbooks-10k-master/books.csv')\n",
    "df_bookList = pd.read_csv('book_list.csv')\n",
    "df_booktags = pd.read_csv('goodbooks-10k-master/book_tags.csv')\n",
    "tags = pd.read_csv('goodbooks-10k-master/tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique number of users:\n",
      "53424\n",
      "unique number of books:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "#Descriptive analysis\n",
    "\n",
    "#unique number of users\n",
    "print('unique number of users:')\n",
    "print(df_rating['user_id'].nunique())\n",
    "\n",
    "#unique number of books\n",
    "print('unique number of books:')\n",
    "print(df_rating['book_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change non-sequential userid factors to sequential factors\n",
    "user_encoding = LabelEncoder()\n",
    "df_rating['user_id_enc'] = user_encoding.fit_transform(df_rating['user_id'].values)\n",
    "n_users = df_rating['user_id_enc'].nunique()\n",
    "\n",
    "book_encoding = LabelEncoder()\n",
    "df_rating['book_id_enc'] = book_encoding.fit_transform(df_rating['book_id'].values)\n",
    "n_books = df_rating['book_id_enc'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodreads_book_id = list(set(df_books.goodreads_book_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add book_tags to df_rating\n",
    "\n",
    "def booktags(goodreads_book_id):\n",
    "    book_tags = []\n",
    "    n = 0\n",
    "\n",
    "    for book_id in goodreads_book_id:\n",
    "        tags = []\n",
    "        for row in df_booktags.itertuples():\n",
    "            if row[1] == book_id:\n",
    "                tags.append(row[2])   \n",
    "        n = n+1        \n",
    "        book_tags.append([book_id, tags])\n",
    "\n",
    "        if n%100 == 0:\n",
    "            print(n,'/',len(goodreads_book_id))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('book_tag.npy', np.array(book_tags))\n",
    "book_tags = np.load('book_tag.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add book tags in book dataframe\n",
    "bt = pd.DataFrame(book_tags)\n",
    "bt.columns = ['goodreads_book_id', 'tags']\n",
    "all_book= pd.merge(df_books, bt, on=\"goodreads_book_id\")\n",
    "book_df = all_book[all_book['language_code'].isin(['en', 'en-CA', 'en-GB', 'en-US','eng'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['book_id', 'goodreads_book_id', 'best_book_id', 'work_id',\n",
       "       'books_count', 'isbn', 'isbn13', 'authors', 'original_publication_year',\n",
       "       'original_title', 'title', 'language_code', 'average_rating',\n",
       "       'ratings_count', 'work_ratings_count', 'work_text_reviews_count',\n",
       "       'ratings_1', 'ratings_2', 'ratings_3', 'ratings_4', 'ratings_5',\n",
       "       'image_url', 'small_image_url', 'tags'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_book = book_df[['book_id', 'goodreads_book_id', 'isbn', 'isbn13', 'authors',\n",
    "       'original_title', 'title', 'language_code', 'average_rating',\n",
    "       'image_url', 'small_image_url', 'tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_book.to_csv('goodreads.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. New User Rating Input Function\n",
    "\n",
    "1. ask user for their favorite genre\n",
    "2. create dataset of user's favorite genre books\n",
    "3. ask user to rate books from the favorite genre book dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "#book tag code for common genres\n",
    "genres_name = ['young-adult','business','action', 'adventure', 'classic', 'graphic-novel','detective', 'true-crime','mystery', 'fantasy', 'historical-fiction', 'fiction', 'horror','romance', 'humor', 'science-fiction', 'suspense', 'non-fiction','thrillers', 'biographies', 'essays', 'self-help', 'memoir','history']\n",
    "genres =[[i[1],i[0]] for g in genres_name for i in tags.values if i[1] == g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres =[[i[0],i[1]] for g in genres_name for i in tags.values if i[1] == g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[33114, 'young-adult'],\n",
       " [5951, 'business'],\n",
       " [1540, 'action'],\n",
       " [1691, 'adventure'],\n",
       " [7404, 'classic'],\n",
       " [13547, 'graphic-novel'],\n",
       " [9336, 'detective'],\n",
       " [31254, 'true-crime'],\n",
       " [20939, 'mystery'],\n",
       " [11305, 'fantasy'],\n",
       " [14487, 'historical-fiction'],\n",
       " [11743, 'fiction'],\n",
       " [14821, 'horror'],\n",
       " [26138, 'romance'],\n",
       " [15048, 'humor'],\n",
       " [26837, 'science-fiction'],\n",
       " [29076, 'suspense'],\n",
       " [21689, 'non-fiction'],\n",
       " [30386, 'thrillers'],\n",
       " [4594, 'biographies'],\n",
       " [10891, 'essays'],\n",
       " [27095, 'self-help'],\n",
       " [19733, 'memoir'],\n",
       " [14552, 'history']]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that asks user about their favorite book genre\n",
    "def favorite_genres(genres):\n",
    "    favorite = []\n",
    "    fav_code = []\n",
    "    for cat, code in genres:\n",
    "        print('Do you like',cat,'?')\n",
    "        print('answer yes or no')\n",
    "        \n",
    "        while True:\n",
    "            ans = input()\n",
    "            \n",
    "            if (ans != 'yes') and (ans != 'no'):\n",
    "                print('wrong input!')\n",
    "            \n",
    "            elif (ans == 'yes'):\n",
    "                favorite.append(cat)\n",
    "                fav_code.append(code)\n",
    "                break\n",
    "            \n",
    "            elif (ans == 'no'):\n",
    "                break\n",
    "                \n",
    "    print (favorite)\n",
    "    return fav_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that creates dataset of user's favorite books\n",
    "def df_favorite_book(u_fav_genre):\n",
    "    result = []\n",
    "    for code in u_fav_genre:\n",
    "        for row in book_df.itertuples():\n",
    "            if code in row[24]:\n",
    "                if list(row)[1:] not in result:\n",
    "                    result.append(list(row)[1:])\n",
    "\n",
    "    df = pd.DataFrame(result, columns=list(book_df.columns))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that asks user to rate books\n",
    "def user_rating(top_books):\n",
    "    user_rating = []\n",
    "    user_rating_count = 0\n",
    "    \n",
    "    bookList = list(top_books[:200])\n",
    "    \n",
    "    while user_rating_count < 30:\n",
    "        twenty_books = random.sample(bookList, 1)\n",
    "\n",
    "        for bookid in twenty_books:\n",
    "            item = df_books[df_books['book_id'] == bookid]  \n",
    "            bookList.remove(bookid)\n",
    "\n",
    "            title = item['title'].values[0]\n",
    "            author = item['authors'].values[0]\n",
    "\n",
    "            print(title,'by', author)\n",
    "            \n",
    "            while True:\n",
    "                rating = input(\"rating for the book: \")\n",
    "                if rating == '':\n",
    "                    break\n",
    "                    print('rated:',user_rating_count,'/30')\n",
    "                elif 1 <= int(rating) <=5:\n",
    "                    user_rating.append([bookid, int(rating)])\n",
    "                    user_rating_count+=1\n",
    "                    print('rated:',user_rating_count,'/30')\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Invalid rating. Must be between 0-5\")\n",
    "                    print('rated:',user_rating_count,'/30')\n",
    "    return user_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cosine Similarity between users and new user\n",
    "\n",
    "1. change array to matrix with NaN as zero (row=user's rating, column = books)\n",
    "2. normalize the user rating\n",
    "3. Fill user's NaN ratings with average rating of user\n",
    "4. Fill user's NaN ratings with average rating of movie\n",
    "\n",
    "*I saved the np arrays into pickles for later usage*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change array to matrix\n",
    "\n",
    "def embedding():\n",
    "    rating_emb = []\n",
    "\n",
    "    for n in range(53424): #53424\n",
    "        u_rating = df_rating[df_rating['user_id_enc']==n].values.tolist()    \n",
    "        user_emb = np.array([0 for u_rating in range(10000)], dtype='f')\n",
    "\n",
    "        for r in u_rating:\n",
    "            user_emb[r[4]] = r[2] \n",
    "\n",
    "        rating_emb.append(user_emb) \n",
    "\n",
    "        if n%1000 ==0:\n",
    "            print(n,'/',53424)\n",
    "    \n",
    "    return rating_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('embedding.npy', emb)\n",
    "# embedding = np.load('embedding.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize user rating\n",
    "def rating_norm(embedding):\n",
    "    norm = []\n",
    "    \n",
    "    for x,n in enumerate(embedding):\n",
    "        zero = np.count_nonzero(n==0)\n",
    "        avg = sum(n)/(len(n)-zero)\n",
    "            \n",
    "        for index, i in enumerate(n):\n",
    "            if i != 0:\n",
    "                n[index] = i-avg\n",
    "        \n",
    "        norm.append(n)\n",
    "\n",
    "        if x%1000 == 0:\n",
    "            print(x,'/53424')\n",
    "                \n",
    "    return norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('r_norm.npy', r_norm)\n",
    "# r_norm = np.load('r_norm.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_avg(rating_emb):\n",
    "    norm = []\n",
    "    \n",
    "    for n in rating_emb:\n",
    "        zero = np.count_nonzero(n==0)\n",
    "        avg = sum(n)/(len(n)-zero)\n",
    "    \n",
    "        for index, i in enumerate(n):\n",
    "            if i != 0:\n",
    "                n[index] = i-avg\n",
    "            else:\n",
    "                n[index] = avg\n",
    "                \n",
    "        norm.append(n)\n",
    "    \n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('user_norm.npy', user_norm)\n",
    "# user_norm = np.load('user_norm.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_average_list(r_norm):\n",
    "    book_avgs = []\n",
    "\n",
    "    for i in range(10000):\n",
    "        x= np.array([row[i] for row in r_norm])\n",
    "        zero = np.count_nonzero(x==0)\n",
    "        avg = sum(x)/(len(x)-zero)\n",
    "        book_avgs.append(avg)\n",
    "\n",
    "        if i%1000 ==0:\n",
    "            print(i,'/',10000)\n",
    "    \n",
    "    return np.array(book_avgs, dtype='f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_norm = np.load('r_norm.npy', allow_pickle=True)\n",
    "# book_avgs = book_average_list(r_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('mov_avg.npy', np.array(mov_avgs, dtype='f'))\n",
    "# book_avgs = np.load('book_avg.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_avg(rating_emb, book_avgs):\n",
    "    book_emb = []\n",
    "    \n",
    "    for index,n in enumerate(rating_emb):\n",
    "        for i,y in enumerate(n):\n",
    "            if y == 0:\n",
    "                n[i] = book_avgs[i] \n",
    "        book_emb.append(n)\n",
    "        \n",
    "        if index%1000 == 0:\n",
    "            print(index,'/', len(rating_emb))\n",
    "    \n",
    "    return book_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_norm = np.load('r_norm.npy', allow_pickle=True) \n",
    "# book_norm = book_avg(r_norm, book_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('book_norm.npy', np.array(book_norm, dtype='f'))\n",
    "book_norm = np.load('book_norm.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33607832,  0.39728734, -0.7451629 , ...,  0.39692053,\n",
       "        -0.09444112,  0.13774939],\n",
       "       [ 0.33607832,  0.5846154 , -0.7451629 , ...,  0.39692053,\n",
       "        -0.09444112,  0.13774939],\n",
       "       [ 0.33607832,  0.39728734, -0.7451629 , ...,  0.39692053,\n",
       "        -0.09444112,  0.13774939],\n",
       "       ...,\n",
       "       [-0.21538462,  0.7846154 , -0.7451629 , ...,  0.39692053,\n",
       "        -0.09444112,  0.13774939],\n",
       "       [-0.45454547,  0.54545456, -0.7451629 , ...,  0.39692053,\n",
       "        -0.09444112,  0.13774939],\n",
       "       [-0.40601504,  0.59398496, -0.40601504, ...,  0.39692053,\n",
       "        -0.09444112,  0.13774939]], dtype=float32)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing rating of new user\n",
    "def norm_newuser(rating_emb):\n",
    "    zero = np.count_nonzero(rating_emb==0)\n",
    "    avg = sum(rating_emb)/(len(rating_emb)-zero)\n",
    "    \n",
    "    norm = [r-avg for r in rating_emb]\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that returns top 10 similar users\n",
    "def top10_sim(user_ratings, newUser_input):\n",
    "    newUser_emb = [rating for book_id, rating in newUser_input]\n",
    "    newUser_rating = norm_newuser(newUser_emb)\n",
    "    newUser_bookid = [book_id for book_id,rating in newUser_input]\n",
    "    \n",
    "    #create a vector of ratings that new user rated books\n",
    "    user_vector = []\n",
    "    for u_rating in user_ratings:\n",
    "        user= []\n",
    "        for index,rating in newUser_input:\n",
    "            user.append(u_rating[index])\n",
    "        user_vector.append(user)\n",
    "        \n",
    "    cosine = []\n",
    "    for user_id, user in enumerate(user_vector):\n",
    "        result = 1 - spatial.distance.cosine(user, newUser_rating)\n",
    "        if np.isnan(result):\n",
    "            cosine.append([user_id,0])\n",
    "        else:\n",
    "            cosine.append([user_id,result])\n",
    "        \n",
    "    cosine.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return cosine[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rating[['user_id_enc', 'book_id_enc']].values \n",
    "y = df_rating['rating'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4781183, 2), (1195296, 2), (4781183,))"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## divide book and user from training data set\n",
    "\n",
    "# column 0 is users and column 1 is books \n",
    "X_train_array = [X_train[:,0], X_train[:, 1]]\n",
    "X_test_array = [X_test[:,0],X_test[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Input, Reshape, Dot, Add, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple neural network w/o bias and activation\n",
    "# 1. Create embedding for user and movie \n",
    "# 2. Dot product user and movie embedding \n",
    "\n",
    "\n",
    "def Recommendation(n_users, n_books, n_emb):\n",
    "    user_input = Input(shape=(1,))\n",
    "    user_emb = Embedding(n_users, n_emb)(user_input)\n",
    "    user = Reshape((n_emb,))(user_emb)\n",
    "    \n",
    "    book_input = Input(shape=(1,))\n",
    "    book_emb = Embedding(n_books, n_emb)(book_input)\n",
    "    book = Reshape((n_emb,))(book_emb)\n",
    "    \n",
    "    output = Dot(axes=1)([user,book]) \n",
    "\n",
    "    model = Model(inputs=[user_input, book_input], outputs=output)\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=opt)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for number of embedding 50 was chosen arbitrarily\n",
    "model = Recommendation(n_users, n_books, n_emb=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set early stopping monitor so the model stops training when it won't improve anymore\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "#train model\n",
    "model.fit(x=X_train_array, y=y_train, batch_size=64 , epochs=5, validation_data=(X_test_array, y_test) , callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network w/ bias and activation\n",
    "# 1. Create embedding for user and movie \n",
    "# 2. Dot product user and movie embedding \n",
    "# 3. Add bias to the dot product\n",
    "# 4. use sigmoid as activation function \n",
    "\n",
    "\n",
    "def Recommendation2(n_users, n_books, n_emb):\n",
    "    user_input = Input(shape=(1,))\n",
    "    user_emb = Embedding(n_users, n_emb)(user_input)\n",
    "    user = Reshape((n_emb,))(user_emb)\n",
    "    user_bias_emb = Embedding(n_users, 1)(user_input)\n",
    "    user_bias = Reshape((1,))(user_bias_emb)\n",
    "    \n",
    "    book_input = Input(shape=(1,))\n",
    "    book_emb = Embedding(n_books, n_emb)(book_input)\n",
    "    book = Reshape((n_emb,))(book_emb)\n",
    "    book_bias_emb = Embedding(n_books, 1)(book_input)\n",
    "    book_bias = Reshape((1,))(book_bias_emb)\n",
    "    \n",
    "    output = Dot(axes=1)([user,book]) \n",
    "    output = Add()([output, user_bias, book_bias])\n",
    "    output = Activation('sigmoid')(output)\n",
    "    output = Lambda(lambda output:output*(5-0)+0)(output) #5 is max rating and 0 is min rating\n",
    "\n",
    "    model = Model(inputs=[user_input, book_input], outputs=output)\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=opt)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Recommendation2(n_users, n_books, n_emb=50)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set early stopping monitor so the model stops training when it won't improve anymore\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "#train model\n",
    "model2.fit(x=X_train_array, y=y_train, batch_size=64 , epochs=5, verbose=1, validation_data=(X_test_array, y_test), callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model \n",
    "\n",
    "# model2.save('nn_model2.h5') \n",
    "\n",
    "model2 = load_model('nn_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 53424\n",
      "1000 / 53424\n",
      "2000 / 53424\n",
      "3000 / 53424\n",
      "4000 / 53424\n",
      "5000 / 53424\n",
      "6000 / 53424\n",
      "7000 / 53424\n",
      "8000 / 53424\n",
      "9000 / 53424\n",
      "10000 / 53424\n",
      "11000 / 53424\n",
      "12000 / 53424\n",
      "13000 / 53424\n",
      "14000 / 53424\n",
      "15000 / 53424\n",
      "16000 / 53424\n",
      "17000 / 53424\n",
      "18000 / 53424\n",
      "19000 / 53424\n",
      "20000 / 53424\n",
      "21000 / 53424\n",
      "22000 / 53424\n",
      "23000 / 53424\n",
      "24000 / 53424\n",
      "25000 / 53424\n",
      "26000 / 53424\n",
      "27000 / 53424\n",
      "28000 / 53424\n",
      "29000 / 53424\n",
      "30000 / 53424\n",
      "31000 / 53424\n",
      "32000 / 53424\n",
      "33000 / 53424\n",
      "34000 / 53424\n",
      "35000 / 53424\n",
      "36000 / 53424\n",
      "37000 / 53424\n",
      "38000 / 53424\n",
      "39000 / 53424\n",
      "40000 / 53424\n",
      "41000 / 53424\n",
      "42000 / 53424\n",
      "43000 / 53424\n",
      "44000 / 53424\n",
      "45000 / 53424\n",
      "46000 / 53424\n",
      "47000 / 53424\n",
      "48000 / 53424\n",
      "49000 / 53424\n",
      "50000 / 53424\n",
      "51000 / 53424\n",
      "52000 / 53424\n",
      "53000 / 53424\n"
     ]
    }
   ],
   "source": [
    "##Predicting using model 2\n",
    "# df_books = pd.read_csv('goodbooks-10k-master/books.csv')\n",
    "books = np.array(list(set(df_rating.book_id_enc)))\n",
    "\n",
    "all_users = []\n",
    "\n",
    "for n in range(n_users):\n",
    "    user = np.array([n for i in range(len(books))])\n",
    "    all_users.append(user)\n",
    "    \n",
    "    if n%1000 ==0:\n",
    "        print(n,'/',n_users)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 53424\n",
      "1000 / 53424\n",
      "2000 / 53424\n",
      "3000 / 53424\n",
      "4000 / 53424\n",
      "5000 / 53424\n",
      "6000 / 53424\n",
      "7000 / 53424\n",
      "8000 / 53424\n",
      "9000 / 53424\n",
      "10000 / 53424\n",
      "11000 / 53424\n",
      "12000 / 53424\n",
      "13000 / 53424\n",
      "14000 / 53424\n",
      "15000 / 53424\n",
      "16000 / 53424\n",
      "17000 / 53424\n",
      "18000 / 53424\n",
      "19000 / 53424\n",
      "20000 / 53424\n",
      "21000 / 53424\n",
      "22000 / 53424\n",
      "23000 / 53424\n",
      "24000 / 53424\n",
      "25000 / 53424\n",
      "26000 / 53424\n",
      "27000 / 53424\n",
      "28000 / 53424\n",
      "29000 / 53424\n",
      "30000 / 53424\n",
      "31000 / 53424\n",
      "32000 / 53424\n",
      "33000 / 53424\n",
      "34000 / 53424\n",
      "35000 / 53424\n",
      "36000 / 53424\n",
      "37000 / 53424\n",
      "38000 / 53424\n",
      "39000 / 53424\n",
      "40000 / 53424\n",
      "41000 / 53424\n",
      "42000 / 53424\n",
      "43000 / 53424\n",
      "44000 / 53424\n",
      "45000 / 53424\n",
      "46000 / 53424\n",
      "47000 / 53424\n",
      "48000 / 53424\n",
      "49000 / 53424\n",
      "50000 / 53424\n",
      "51000 / 53424\n",
      "52000 / 53424\n",
      "53000 / 53424\n"
     ]
    }
   ],
   "source": [
    "# create dataframe with rating\n",
    "rating_emb = []\n",
    "\n",
    "for n,u_emb in enumerate(all_users):\n",
    "    predictions = model2.predict([u_emb, books])\n",
    "    predictions = np.array([p[0] for p in predictions])\n",
    "    rating_emb.append(predictions)\n",
    "\n",
    "    if n%1000 ==0:\n",
    "        print(n,'/', len(all_users))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top10_book_suggestion(rating_emb, method, scores):\n",
    "    top10_books = []\n",
    "    userid = method[scores.index(max(scores))]\n",
    "    top10 = np.argsort(rating_emb[userid])[-10:]\n",
    "    \n",
    "    for bookid in top10:\n",
    "        top10_books.append(df_books[df_books['book_id'] == bookid]['title'])\n",
    "    \n",
    "    return top10_books\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting all the functions together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you like young-adult ?\n",
      "answer yes or no\n",
      "no\n",
      "Do you like business ?\n",
      "answer yes or no\n",
      "yes\n",
      "Do you like action ?\n",
      "answer yes or no\n",
      "no\n",
      "Do you like adventure ?\n",
      "answer yes or no\n",
      "no\n",
      "Do you like classic ?\n",
      "answer yes or no\n",
      "no\n",
      "Do you like graphic-novel ?\n",
      "answer yes or no\n",
      "no\n",
      "Do you like detective ?\n",
      "answer yes or no\n",
      "no\n",
      "Do you like true-crime ?\n",
      "answer yes or no\n",
      "no\n",
      "Do you like mystery ?\n",
      "answer yes or no\n",
      "no\n",
      "Do you like fantasy ?\n",
      "answer yes or no\n",
      "no\n",
      "Do you like fiction ?\n",
      "answer yes or no\n",
      "no\n",
      "Do you like horror ?\n",
      "answer yes or no\n",
      "no\n",
      "Do you like romance ?\n",
      "answer yes or no\n",
      "no\n",
      "Do you like humor ?\n",
      "answer yes or no\n",
      "no\n",
      "Do you like science-fiction ?\n",
      "answer yes or no\n",
      "no\n",
      "Do you like suspense ?\n",
      "answer yes or no\n",
      "no\n",
      "Do you like non-fiction ?\n",
      "answer yes or no\n",
      "no\n",
      "Do you like thrillers ?\n",
      "answer yes or no\n",
      "no\n",
      "Do you like biographies ?\n",
      "answer yes or no\n",
      "no\n",
      "Do you like essays ?\n",
      "answer yes or no\n",
      "no\n",
      "Do you like self-help ?\n",
      "answer yes or no\n",
      "no\n",
      "Do you like memoir ?\n",
      "answer yes or no\n",
      "no\n",
      "Do you like history ?\n",
      "answer yes or no\n",
      "no\n",
      "['business']\n"
     ]
    }
   ],
   "source": [
    "u_fav_genre = favorite_genres(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_books = df_favorite_book(u_fav_genre).sort_values(['average_rating'], ascending=False)['book_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Notice: A True Story of High Finance, Murder, and One Man’s Fight for Justice by Bill Browder\n",
      "rating for the book: \n",
      "Barbarians at the Gate: The Fall of RJR Nabisco by Bryan Burrough, John Helyar\n",
      "rating for the book: \n",
      "The Honest Truth About Dishonesty: How We Lie to Everyone - Especially Ourselves by Dan Ariely\n",
      "rating for the book: \n",
      "Made to Stick: Why Some Ideas Survive and Others Die by Chip Heath, Dan Heath\n",
      "rating for the book: \n",
      "Too Big to Fail: The Inside Story of How Wall Street and Washington Fought to Save the Financial System from Crisis — and Themselves by Andrew Ross Sorkin\n",
      "rating for the book: \n",
      "Fermat's Enigma: The Epic Quest to Solve the World's Greatest Mathematical Problem by Simon Singh\n",
      "rating for the book: \n",
      "Good to Great: Why Some Companies Make the Leap... and Others Don't by James C. Collins\n",
      "rating for the book: \n",
      "The Design of Everyday Things by Donald A. Norman\n",
      "rating for the book: \n",
      "The Medium is the Massage by Marshall McLuhan, Quentin Fiore, Jerome Agel\n",
      "rating for the book: \n",
      "Zero to One: Notes on Startups, or How to Build the Future by Peter Thiel, Blake  Masters\n",
      "rating for the book: 2\n",
      "rated: 1 /30\n",
      "The Art of Seduction by Robert Greene\n",
      "rating for the book: 4\n",
      "rated: 2 /30\n",
      "The Element: How Finding Your Passion Changes Everything by Ken Robinson, Lou Aronica\n",
      "rating for the book: 2\n",
      "rated: 3 /30\n",
      "The Magic (The Secret, #3) by Rhonda Byrne\n",
      "rating for the book: 3\n",
      "rated: 4 /30\n",
      "The Power of Habit: Why We Do What We Do in Life and Business by Charles Duhigg\n",
      "rating for the book: 4\n",
      "rated: 5 /30\n",
      "Flow: The Psychology of Optimal Experience by Mihaly Csikszentmihalyi\n",
      "rating for the book: 2\n",
      "rated: 6 /30\n",
      "The Path Between the Seas: The Creation of the Panama Canal, 1870-1914 by David McCullough\n",
      "rating for the book: 1\n",
      "rated: 7 /30\n",
      "Freakonomics: A Rogue Economist Explores the Hidden Side of Everything (Freakonomics, #1) by Steven D. Levitt, Stephen J. Dubner\n",
      "rating for the book: 3\n",
      "rated: 8 /30\n",
      "Better: A Surgeon's Notes on Performance by Atul Gawande\n",
      "rating for the book: \n",
      "Founders at Work: Stories of Startups' Early Days by Jessica Livingston\n",
      "rating for the book: 3\n",
      "rated: 9 /30\n",
      "When Genius Failed: The Rise and Fall of Long-Term Capital Management by Roger Lowenstein\n",
      "rating for the book: 4\n",
      "rated: 10 /30\n",
      "Einstein: His Life and Universe by Walter Isaacson\n",
      "rating for the book: 2\n",
      "rated: 11 /30\n",
      "The Five Dysfunctions of a Team: A Leadership Fable by Patrick Lencioni\n",
      "rating for the book: 4\n",
      "rated: 12 /30\n",
      "Business Model Generation by Alexander Osterwalder, Yves Pigneur\n",
      "rating for the book: 2\n",
      "rated: 13 /30\n",
      "The 7 Habits of Highly Effective Teens: The Ultimate Teenage Success Guide by Sean Covey\n",
      "rating for the book: 1\n",
      "rated: 14 /30\n",
      "Kitchen Confidential: Adventures in the Culinary Underbelly by Anthony Bourdain\n",
      "rating for the book: 4\n",
      "rated: 15 /30\n",
      "The Blind Side: Evolution of a Game by Michael   Lewis\n",
      "rating for the book: 2\n",
      "rated: 16 /30\n",
      "The Gifts of Imperfection: Let Go of Who You Think You're Supposed to Be and Embrace Who You Are by Brené Brown\n",
      "rating for the book: 4\n",
      "rated: 17 /30\n",
      "Where Good Ideas Come From: The Natural History of Innovation by Steven Johnson\n",
      "rating for the book: 2\n",
      "rated: 18 /30\n",
      "The Subtle Art of Not Giving a F*ck: A Counterintuitive Approach to Living a Good Life by Mark Manson\n",
      "rating for the book: 3\n",
      "rated: 19 /30\n",
      "Meditations by Marcus Aurelius, Martin Hammond, Diskin Clay\n",
      "rating for the book: 4\n",
      "rated: 20 /30\n",
      "Writing Down the Bones: Freeing the Writer Within by Natalie Goldberg\n",
      "rating for the book: 2\n",
      "rated: 21 /30\n",
      "The Purpose Driven Life: What on Earth Am I Here for? by Rick Warren\n",
      "rating for the book: 3\n",
      "rated: 22 /30\n",
      "Great by Choice: Uncertainty, Chaos, and Luck--Why Some Thrive Despite Them All by James C. Collins, Morten T. Hansen\n",
      "rating for the book: 4\n",
      "rated: 23 /30\n",
      "On Writing Well: The Classic Guide to Writing Nonfiction by William Zinsser\n",
      "rating for the book: 1\n",
      "rated: 24 /30\n",
      "The Bully Pulpit: Theodore Roosevelt, William Howard Taft, and the Golden Age of Journalism by Doris Kearns Goodwin\n",
      "rating for the book: 2\n",
      "rated: 25 /30\n",
      "SuperFreakonomics: Global Cooling, Patriotic Prostitutes And Why Suicide Bombers Should Buy Life Insurance by Steven D. Levitt, Stephen J. Dubner\n",
      "rating for the book: 4\n",
      "rated: 26 /30\n",
      "No Place to Hide: Edward Snowden, the NSA, and the U.S. Surveillance State by Glenn Greenwald\n",
      "rating for the book: 2\n",
      "rated: 27 /30\n",
      "From Beirut to Jerusalem by Thomas L. Friedman\n",
      "rating for the book: 3\n",
      "rated: 28 /30\n",
      "The Everything Store: Jeff Bezos and the Age of Amazon by Brad Stone\n",
      "rating for the book: 4\n",
      "rated: 29 /30\n",
      "Mindset: The New Psychology of Success by Carol S. Dweck\n",
      "rating for the book: 2\n",
      "rated: 30 /30\n"
     ]
    }
   ],
   "source": [
    "newUser_input = user_rating(top_books)\n",
    "newUser_embedding = [n[1] for n in newUser_input]\n",
    "newUser_emb = norm_newuser(newUser_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_norm = np.load('r_norm.npy', allow_pickle=True)\n",
    "zero = top10_sim(r_norm, newUser_input)\n",
    "\n",
    "user_norm = np.load('user_norm.npy', allow_pickle=True)\n",
    "user = top10_sim(user_norm, newUser_input)\n",
    "\n",
    "book_norm = np.load('book_norm.npy')\n",
    "book = top10_sim(book_norm, newUser_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "method =[zero[0][0], user[0][0], book[0][0]]\n",
    "scores = [zero[0][1], user[0][1], book[0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1902    Son (The Giver, #4)\n",
       " Name: title, dtype: object, 1616    Without Fail (Jack Reacher, #6)\n",
       " Name: title, dtype: object, 2588    Certain Girls (Cannie Shapiro #2)\n",
       " Name: title, dtype: object, 2080    Skin Game (The Dresden Files, #15)\n",
       " Name: title, dtype: object, 1893    Wedding Night\n",
       " Name: title, dtype: object, 502    2001: A Space Odyssey (Space Odyssey, #1)\n",
       " Name: title, dtype: object, 1613    We'll Always Have Summer (Summer, #3)\n",
       " Name: title, dtype: object, 2147    Monster\n",
       " Name: title, dtype: object, 2505    Casino Royale (James Bond, #1)\n",
       " Name: title, dtype: object, 3249    Shopgirl\n",
       " Name: title, dtype: object]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_book_suggestion(rating_emb, method, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
